{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: NLTK and Machine Learning Pipelines\n",
    "### By: Samantha Cohen\n",
    "### Uniqname: samcoh\n",
    "\n",
    "In this final homework assignment, you'll be bringing together ideas from Natural Language Processing as well as\n",
    "Machine Learning Pipelines.  This assignment uses materials adapted from [Benjamin Bengfort](https://bbengfort.github.io/tutorials/2016/05/19/text-classification-nltk-sckit-learn.html).\n",
    "\n",
    "We are going back to work that you did in previous courses with object-oriented Python to create a proprocessor\n",
    "to do NLP on some text in the context of machine learning pipelines.\n",
    "\n",
    "First, we are going to review code that you should find reusable and helpful moving forward.  There's a lot of setup \n",
    "for this homework assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "import re #added this import \n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "from bokeh.layouts import layout\n",
    "from bokeh.layouts import widgetbox\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.io import show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import Text\n",
    "from bokeh.models import Plot\n",
    "from bokeh.models import Title\n",
    "from bokeh.models import Slider\n",
    "from bokeh.models import Circle\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.models import CustomJS\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.models import LinearAxis\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models import SingleIntervalTicker\n",
    "from bokeh.plotting import figure\n",
    "#from bokeh.palettes import Spectral6\n",
    "from bokeh.palettes import plasma\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "\n",
    "# from random import sample \n",
    "from scipy import stats \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#better lemmer \n",
    "#better part of speech\n",
    "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    #init is a constructor, give it arguments. They are keyword arguments \n",
    "    def __init__(self, \n",
    "                 stopwords=None, \n",
    "                 punct=None,\n",
    "                 lower=True, \n",
    "                 strip=True):\n",
    "        self.lower = lower\n",
    "        self.strip = strip\n",
    "        self.punct = punct or set(string.punctuation)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        ##ADDED BELOW\n",
    "        \n",
    "        #get a set of english stop words and assign the value to the variable stopwords_to_use \n",
    "        stopwords_to_use = set(sw.words('english'))\n",
    "        #create a list of string numbers to add to the set stopwords_to_use \n",
    "        add_nums = [\"0\",\"1\",\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "        ## for each string-number in the list add_nums add each string-number to the stopwords_to_use set \n",
    "        for num in add_nums:\n",
    "            stopwords_to_use.add(num)\n",
    "        \n",
    "        self.stopwords  = stopwords or set(stopwords_to_use) \n",
    "       \n",
    " \n",
    "    #dont change \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    #dont change\n",
    "    def inverse_transform(self, X):\n",
    "        return [\" \".join(doc) for doc in X]\n",
    "    #dont change \n",
    "    def transform(self, X):  #transform call tokenizes \n",
    "        return [\n",
    "            list(self.tokenize(doc)) for doc in X\n",
    "        ]\n",
    "    #lemmatizer does a better job between run the verb and ran the noun \n",
    "    def tokenize(self, document):\n",
    "        ##ADDED BELOW: \n",
    "            ##get rid of the html tags using regex using this pattern \n",
    "        pattern = re.compile('<.*?>') \n",
    "     \n",
    "        ## Break the document w/out html tag into sentences using sent_tokenize \n",
    "        for sent in sent_tokenize(document): \n",
    "            \n",
    "            #removes the html tags from the sentence \n",
    "            sent = re.sub(pattern,'', sent)   #this replaces the html tags with an empty string \n",
    "            \n",
    "            # Break the sentence into part of speech tagged tokens\n",
    "            for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "                # Apply preprocessing to the token\n",
    "                token = token.lower() if self.lower else token\n",
    "                token = token.strip() if self.strip else token\n",
    "                token = token.strip('_') if self.strip else token\n",
    "                token = token.strip('*') if self.strip else token\n",
    "\n",
    "                # If stopword, ignore token and continue\n",
    "                if token in self.stopwords:\n",
    "                    continue \n",
    "\n",
    "                # If punctuation, ignore token and continue\n",
    "                if all(char in self.punct for char in token):\n",
    "                    continue\n",
    "\n",
    "                # Lemmatize the token and yield\n",
    "                lemma = self.lemmatize(token, tag)\n",
    "                yield lemma #next time call this you pick up where you left off \n",
    "\n",
    "    def lemmatize(self, token, tag): #our part of speech tag form. N or P. Look at first chacracter \n",
    "        tag = {\n",
    "            'N': wn.NOUN,\n",
    "            'V': wn.VERB,\n",
    "            'R': wn.ADV,\n",
    "            'J': wn.ADJ\n",
    "        }.get(tag[0], wn.NOUN)\n",
    "\n",
    "        return self.lemmatizer.lemmatize(token, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just takes text and returns it unmodified.  We need it in the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_tokenizer(text): #create null function and takes some text and returns that text \n",
    "    #does not change anything just returns the identity - the text itself \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report as clsr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def build_and_evaluate(X, y,\n",
    "    classifier=SGDClassifier, outpath=None, verbose=True):\n",
    "\n",
    "    def build(classifier, X, y=None):\n",
    "        \"\"\"\n",
    "        Inner build function that builds a single model.\n",
    "        \"\"\"\n",
    "        #dont have instance of classifier than generate instance of classifier \n",
    "        if isinstance(classifier, type):\n",
    "            classifier = classifier()\n",
    "        #this is a pipeline. \n",
    "        model = Pipeline([\n",
    "            ('preprocessor', NLTKPreprocessor()),#calling class we created \n",
    "            ('vectorizer', TfidfVectorizer(  \n",
    "                tokenizer=identity_tokenizer, # note that this will fail unless you use the identity_tokenizer\n",
    "                preprocessor=None, lowercase=False\n",
    "            )), \n",
    "            ('classifier', classifier), #SET TO WHATEVER YOU PASS IN \n",
    "        ])\n",
    "\n",
    "        model.fit(X, y) #fit model with train data passed in \n",
    "        return model\n",
    "\n",
    "    # Label encode the targets\n",
    "    labels = LabelEncoder()\n",
    "    y = labels.fit_transform(y) #fit_transform on label encoder and assign it back to y \n",
    "\n",
    "    # Begin evaluation\n",
    "    if verbose: print(\"Building for evaluation\")\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    model = build(classifier, X_train, y_train)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Evaluation model fit in {:0.3f} seconds\".format(time.time() - start_time))\n",
    "        print(\"Classification Report:\\n\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(clsr(y_test, y_pred, target_names=labels.classes_))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Building complete model and saving ...\")\n",
    "    start_time = time.time()\n",
    "    model = build(classifier, X, y)\n",
    "    model.labels_ = labels\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Complete model fit in {:0.3f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "    if outpath:\n",
    "        with open(outpath, 'wb') as f:\n",
    "            pickle.dump(model, f) #pickel save object and load it back in again \n",
    "\n",
    "        print(\"Model written out to {}\".format(outpath))\n",
    "        \n",
    "    #added line below to check to see the accuracy score of every model \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return model, score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got everything set up for our pipelines, we can load some data.  Here we're going to use the Movie Reviews\n",
    "corpus from the NLTK package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 reviews\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews as reviews\n",
    "\n",
    "X = [reviews.raw(fileid) for fileid in reviews.fileids()]\n",
    "y = [reviews.categories(fileid)[0] for fileid in reviews.fileids()]\n",
    "print(\"There are {} reviews\".format(len(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews.raw('neg/cv000_29416.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews.raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can take a closer look at the structure of 'reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"movie_reviews_model.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation\n",
      "Evaluation model fit in 53.401 seconds\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.78      0.80      0.79       200\n",
      "         pos       0.79      0.78      0.79       200\n",
      "\n",
      "    accuracy                           0.79       400\n",
      "   macro avg       0.79      0.79      0.79       400\n",
      "weighted avg       0.79      0.79      0.79       400\n",
      "\n",
      "Building complete model and saving ...\n",
      "Complete model fit in 63.972 seconds\n",
      "Model written out to movie_reviews_model.pickle\n"
     ]
    }
   ],
   "source": [
    "# PATH = \"movie_reviews_model.pickle\"\n",
    "model = build_and_evaluate(X,y, classifier=SGDClassifier, outpath=PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how much of the positives were negative \n",
    "#interested in accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, building a model takes a considerable amount of time (and resources), so we're going to use the\n",
    "\"pickled\" version of the model so we don't have to recreate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0]\n",
      "['neg' 'pos' 'neg' 'neg']\n"
     ]
    }
   ],
   "source": [
    "#load saved model and predict \n",
    "with open(PATH, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "yhat = model.predict([\n",
    "    \"This is the worst movie I have ever seen!\",\n",
    "    \"The movie was great action packed and full of adventure!\",\n",
    "    \"Wow!\",\n",
    "    \"This was the best and the worst at the same time!\"\n",
    "])\n",
    "\n",
    "\n",
    "print(yhat) #0 1 0 0 \n",
    "print(model.labels_.inverse_transform(yhat))\n",
    "#map on to labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can take a look to see which words are most highly associated with each sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def show_most_informative_features(model, text=None, n=20):\n",
    "    # Extract the vectorizer and the classifier from the pipeline\n",
    "    vectorizer = model.named_steps['vectorizer']\n",
    "    classifier = model.named_steps['classifier']\n",
    "\n",
    "    # Check to make sure that we can perform this computation\n",
    "    if not hasattr(classifier, 'coef_'):\n",
    "        raise TypeError(\n",
    "            \"Cannot compute most informative features on {}.\".format(\n",
    "                classifier.__class__.__name__\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if text is not None:\n",
    "        # Compute the coefficients for the text\n",
    "        tvec = model.transform([text]).toarray()\n",
    "    else:\n",
    "        # Otherwise simply use the coefficients\n",
    "        tvec = classifier.coef_\n",
    "\n",
    "    # Zip the feature names with the coefs and sort\n",
    "    coefs = sorted(\n",
    "        zip(tvec[0], vectorizer.get_feature_names()),\n",
    "        key=itemgetter(0), reverse=True\n",
    "    )\n",
    "\n",
    "    # Get the top n and bottom n coef, name pairs\n",
    "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
    "\n",
    "    # Create the output string to return\n",
    "    output = []\n",
    "\n",
    "    # If text, add the predicted value to the output.\n",
    "    if text is not None:\n",
    "        output.append(\"\\\"{}\\\"\".format(text))\n",
    "        output.append(\n",
    "            \"Classified as: {}\".format(model.predict([text]))\n",
    "        )\n",
    "        output.append(\"\")\n",
    "\n",
    "    # Create two columns with most negative and most positive features.\n",
    "    for (cp, fnp), (cn, fnn) in topn:\n",
    "        output.append(\n",
    "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(\n",
    "                cp, fnp, cn, fnn\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6828            fun    -4.7290            bad\n",
      "2.5205          great    -2.6989  unfortunately\n",
      "2.0901    performance    -2.5090          waste\n",
      "2.0830            see    -2.4804        nothing\n",
      "1.9792         matrix    -2.4689           plot\n",
      "1.8342          quite    -2.4475        suppose\n",
      "1.7137      memorable    -2.4316        attempt\n",
      "1.6940           trek    -1.9850           poor\n",
      "1.6509       bulworth    -1.9788          awful\n",
      "1.6446      different    -1.9238         boring\n",
      "1.5903       terrific    -1.9236           look\n",
      "1.5618        portray    -1.8875         stupid\n",
      "1.5411      hilarious    -1.8327          guess\n",
      "1.5374           also    -1.7941     ridiculous\n",
      "1.5323            job    -1.7805           even\n",
      "1.5192        overall    -1.7333         script\n",
      "1.5005      excellent    -1.6732          could\n",
      "1.4982     especially    -1.6669      carpenter\n",
      "1.4896           true    -1.6149         anyway\n",
      "1.4777      enjoyable    -1.5915           lame\n"
     ]
    }
   ],
   "source": [
    "print(show_most_informative_features(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your challenge:\n",
    "Build a sentiment classifier for the IMDB Dataset, which is available in the data/ directory.  Please note that\n",
    "the IMDB Dataset consists of 50000 rows, so it's probably best to do most of your work on a sample of the\n",
    "original dataset.  In the code below we use a sample size of 1000.  That's probably fine to start with but your final submission should be based on a sample of at least 5000.\n",
    "\n",
    "You should attempt to improve the default classifier shown above by trying to get a higher accuracy score.  For example, you might want to try one of the other classifiers from the list shown in class 22.  Another way to improve your pipeline is to spend more time\n",
    "building a better text preprocessor (e.g. you can see some reviews contain HTML, which you might decide to strip out).  Another thing you might want to do is to look more closely at the stopword list.\n",
    "\n",
    "Please note that if you resample the dataset you will get slightly different accuracy values.  The values should not fluctuate wildly, so don't get too concerned about their absolute value.  What we're looking for is an improvement from the baseline and evidence that you tried a variety of approaches to improving the classifier.  We're also looking for evidence that you can manipulate text data into a machine learning pipeline and correctly interpret the results.\n",
    "\n",
    "You should include code and interpretation of your results in this notebook.   If you tried many different approaches and ultimately chose one over the others, please include that in your write-up.  You do not need to include code for analyses that you discarded.\n",
    "\n",
    "You should be able to plug the new data into the old pipeline code to get started (another handy thing about pipelines) and then start experimenting with improving the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in IMBD Data and take a sample of 5000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_csv(\"data/imdb-dataset-of-50k-movie-reviews.zip\") #handles a zip file \n",
    "# Let's do most of our work on a smaller sample of the 50000 rows\n",
    "m = m.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11936</th>\n",
       "      <td>I liked this film very much. The story jumps b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30205</th>\n",
       "      <td>Dear me. Where do I start? The dad isn't anywh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48567</th>\n",
       "      <td>I saw The D's new film tonight at a special ad...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36385</th>\n",
       "      <td>The only reason I bought the DVD was to satisf...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31602</th>\n",
       "      <td>I have never been a great fan of Oliver Stone,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "11936  I liked this film very much. The story jumps b...  positive\n",
       "30205  Dear me. Where do I start? The dad isn't anywh...  negative\n",
       "48567  I saw The D's new film tonight at a special ad...  positive\n",
       "36385  The only reason I bought the DVD was to satisf...  negative\n",
       "31602  I have never been a great fan of Oliver Stone,...  positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. In the DataFrame m, assign columns review and sentiment to variables X and y. X is all the variables, in this case reviews, that will be used to predict the type of sentiment. The variable y is the categorical variable sentiment. \n",
    "- X is the features, in this case reviews, that will be used to try and figure out the classification. \n",
    "- The values of variable y is what we are trying to predict. In this case, we are trying to predict a review's sentiment based on words used in review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT YOUR CODE AND INTERPRETATION IN MULTIPLE CELLS BELOW THIS ONE\n",
    "X = m[\"review\"]\n",
    "y = m[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explanation of Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of Improvement: \n",
    "\n",
    "**1) Improve preprocessor**\n",
    "1. *Added string-numbers to the list of Stopwords*:  I improved the preprocessor by adding string numbers to the list of stopwords (0-9 were added). I did this because before numbers such as 7 and 8 were important features that were used to classify a review as having positive sentiment. After looking into this, I realized that numbers were not predictive of positive sentiment because you do not know the scale that reviewer is rating the movie out of. A reviewer could rate a movie as 7/10 or 7/100. Therefore, numbers are not a good feature to use when predicting sentiment so it is best remove them as a word feature. \n",
    "\n",
    "        class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
    "            #init is a constructor, give it arguments. They are keyword arguments \n",
    "            def __init__(self, \n",
    "                         stopwords=None, \n",
    "                         punct=None,\n",
    "                         lower=True, \n",
    "                         strip=True):\n",
    "                self.lower = lower\n",
    "                self.strip = strip\n",
    "                self.punct = punct or set(string.punctuation)\n",
    "                self.lemmatizer = WordNetLemmatizer()\n",
    "                \n",
    "                ##ADDED BELOW\n",
    "                \n",
    "                #get a set of english stop words and assign the value to the variable stopwords_to_use \n",
    "                stopwords_to_use = set(sw.words('english'))\n",
    "                \n",
    "                #create a list of string numbers to add to the set stopwords_to_use  \n",
    "                add_nums = [\"0\",\"1\",\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "                \n",
    "                ## for each string number in the list add_nums add the number to the stopwords_to_use set \n",
    "                for num in add_nums:\n",
    "                    stopwords_to_use.add(num)\n",
    "\n",
    "                self.stopwords  = stopwords or set(stopwords_to_use) \n",
    "           ...\n",
    "\n",
    "\n",
    "2. *Removed HTML Tags*: I improved the preprocessor by taking out HTML tags using regex. I made these changes within the class NLTKPreprocessor under the method tokenize. Below I copied and pasted the code I changed in the method above, and described the changes. \n",
    "\n",
    "        ...\n",
    "\n",
    "         def tokenize(self, document):\n",
    "            ##ADDED BELOW: \n",
    "                ##get rid of the html tags using regex using this pattern \n",
    "            pattern = re.compile('<.*?>') \n",
    "\n",
    "            ## Split the document into sentences using sent_tokenize \n",
    "            for sent in sent_tokenize(document): \n",
    "\n",
    "                #removes the html tags from the sentence \n",
    "                sent = re.sub(pattern,'', sent)   #this replaces the html tags with an empty string \n",
    "                ...\n",
    "        ...\n",
    "    I used regex to take out the html tags within each sentence. I replaced the html tag with an empty string. I did this by using the methods compile and sub. The compile method allowed me to compile a regular expression pattern into a regular expression object (https://docs.python.org/2/library/re.html). As well, the method sub allowed me to return a string that replaces html tags with an empty string. The method sub does this by replacing the leftmost non-overlapping occurrences of the pattern in string by using a replacement string specified. The method sub, uses the pattern created in compile to find the html tags. \n",
    "\n",
    "    Below I exemplify how the code block I added works. In the example below, I took a random review from the sample dataset. Afterwards, I used string_tokenized on the review, to split the review into sentences, and looped through each sentence in the list. I used the re.compile and re.sub to make changes to the string if an html tag is present. I printed the string before it is altered, and the string after it is altered. As you can see, if there is no tags the string is returned unchanged, but when tags are present they are removed and replaced with an empty string. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_change =m[\"review\"].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before: \n",
      "\tI saw The D's new film tonight at a special advance screening, and I was so blown away by its sheer greatness that I felt I had to come onto IMDb and get the word out.\n",
      "\n",
      "After: \n",
      "\tI saw The D's new film tonight at a special advance screening, and I was so blown away by its sheer greatness that I felt I had to come onto IMDb and get the word out.\n",
      "\n",
      "Before: \n",
      "\tAdmittedly, I was already a huge fan of the D's work - I loved the HBO series and listen to their music weekly (there's nothing better to sing along to), but this appreciation actually made me more apprehensive going into to tonight's screening (for we've all been disappointed one time or another by something we love when it attempted to make the jump to the big screen).\n",
      "\n",
      "After: \n",
      "\tAdmittedly, I was already a huge fan of the D's work - I loved the HBO series and listen to their music weekly (there's nothing better to sing along to), but this appreciation actually made me more apprehensive going into to tonight's screening (for we've all been disappointed one time or another by something we love when it attempted to make the jump to the big screen).\n",
      "\n",
      "Before: \n",
      "\tWith Tenacious D's \"The Pick of Destiny,\" this is not the case.<br /><br />Simply put, this film rocks harder than anything I've seen and is funnier and more majestic than anything Peter Jackson, Pixar, and Will Ferrell together could produce.\n",
      "\n",
      "After: \n",
      "\tWith Tenacious D's \"The Pick of Destiny,\" this is not the case.Simply put, this film rocks harder than anything I've seen and is funnier and more majestic than anything Peter Jackson, Pixar, and Will Ferrell together could produce.\n",
      "\n",
      "Before: \n",
      "\tIt tells the story of the D before we came to know them, setting up intriguing histories of Kage and Jables' upbringings, their comings together, and how they were inspired to write songs about such things as Lee, Sasquatch, and Dio.\n",
      "\n",
      "After: \n",
      "\tIt tells the story of the D before we came to know them, setting up intriguing histories of Kage and Jables' upbringings, their comings together, and how they were inspired to write songs about such things as Lee, Sasquatch, and Dio.\n",
      "\n",
      "Before: \n",
      "\tMost importantly, they reveal the true inspiration to the Greatest Song In The World, \"Tribute,\" and how it came to be (which is different than the HBO Series' version).\n",
      "\n",
      "After: \n",
      "\tMost importantly, they reveal the true inspiration to the Greatest Song In The World, \"Tribute,\" and how it came to be (which is different than the HBO Series' version).\n",
      "\n",
      "Before: \n",
      "\tAfter you've witnessed it you probably won't be able to remember it (hence the Tribute), but your mind forever be changes by its genius.<br /><br />I don't go out to movies very often anymore due to the high ticket price and the hassle of getting parking, paying outrageous concession prices, etc., but I usually make exceptions when it's starring someone I really love or concerning something of the the same variety.\n",
      "\n",
      "After: \n",
      "\tAfter you've witnessed it you probably won't be able to remember it (hence the Tribute), but your mind forever be changes by its genius.I don't go out to movies very often anymore due to the high ticket price and the hassle of getting parking, paying outrageous concession prices, etc., but I usually make exceptions when it's starring someone I really love or concerning something of the the same variety.\n",
      "\n",
      "Before: \n",
      "\t\"The Pick of Destiny\" was so good that I have no qualms going back to see it again when it releases nationwide, and I plan on convincing all of my friends to go, too.\n",
      "\n",
      "After: \n",
      "\t\"The Pick of Destiny\" was so good that I have no qualms going back to see it again when it releases nationwide, and I plan on convincing all of my friends to go, too.\n",
      "\n",
      "Before: \n",
      "\tLast week we saw \"Borat\" and loved it, but this is honest to goodness TEN TIMES BETTER.\n",
      "\n",
      "After: \n",
      "\tLast week we saw \"Borat\" and loved it, but this is honest to goodness TEN TIMES BETTER.\n",
      "\n",
      "Before: \n",
      "\tFor anyone who truly loves rock music and comedic brilliance, see this film.\n",
      "\n",
      "After: \n",
      "\tFor anyone who truly loves rock music and comedic brilliance, see this film.\n",
      "\n",
      "Before: \n",
      "\tThese guys' talent is so great you should have no hesitation supporting their cause.\n",
      "\n",
      "After: \n",
      "\tThese guys' talent is so great you should have no hesitation supporting their cause.\n",
      "\n",
      "Before: \n",
      "\tYou will not be disappointed, and the Rock Lords will smile upon you favorably.\n",
      "\n",
      "After: \n",
      "\tYou will not be disappointed, and the Rock Lords will smile upon you favorably.\n"
     ]
    }
   ],
   "source": [
    "string_tokenized_example = sent_tokenize(string_to_change)\n",
    "n = 1 \n",
    "for x in string_tokenized_example: \n",
    "    print(\"\\nBefore: \")\n",
    "    print('\\t' + x)\n",
    "    print(\"\\nAfter: \")\n",
    "    pattern = re.compile('<.*?>')\n",
    "    sent = re.sub(pattern, '', x)\n",
    "    print('\\t'+ sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**2) Altered build_and_evaluate**\n",
    "\n",
    "1. I also altered the function build_and_evaluate. I altered the function by adding a line the calculates the accuracy score of the model. Before, this function returned one object, the model, but now it returns a tuple: the model and the model's accuracy score. Therefore, the function now returns the model object and an integer representing the accuracy score. \n",
    "\n",
    "        def build_and_evaluate(X, y,\n",
    "            classifier=SGDClassifier, outpath=None, verbose=True):\n",
    "\n",
    "             ...\n",
    "         \n",
    "            #added line below to check to see the accuracy score of every model \n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            return model, score \n",
    "\n",
    "    I made this change so I was able to test multiple classifiers and compare the accuracy score of each model to one another; thereby, allowing me to compare and choose the model with the best accuracy score. The necessity of this change is further shown in part 4. \n",
    "    \n",
    "    \n",
    "**3) Added import statments to the top of the notebook**\n",
    "\n",
    "1. Another change i made to the notebook is importing addition modules that I needed. This is shown at the top of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evidence of multiple classifiers attempted\n",
    "- Tried a total of 8  classifiers:  \n",
    "    1. \"KNeighborsClassifier\"\n",
    "    2. \"SVC\"\n",
    "    3. \"NuSVC\"\n",
    "    4. \"DecisionTreeClassifier\"\n",
    "    5. \"RandomForestClassifier\"\n",
    "    6. \"AdaBoostClassifier\"\n",
    "    7. \"GradientBoostingClassifier\"\n",
    "    8. \"SGDClassifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Create a Path that will pickle the model with the highest accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"My_IMDB_movie_reviews_model.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Create a List of classifiers to try, and a list of classifier_names. Afterwards, use a for loop to try all the classifiers within the list classifiers. \n",
    "- When iterating through the list of classifiers, create a dictionary called classifier_accuracy_score that has the classifier name as the key and the accuracy score of the model as the value. \n",
    "- Overwrite the pickle file with the new model if the model has the highest accuracy score. Therefore, in the end the pickle file will store the model object with the highest accuracy score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(nu=0.1,probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(), \n",
    "    SGDClassifier()\n",
    "    ]\n",
    "classifier_names = [\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"SVC\",\n",
    "    \"NuSVC\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"GradientBoostingClassifier\", \n",
    "    \"SGDClassifier\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Type: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform')\n",
      "Building for evaluation\n",
      "Evaluation model fit in 44.787 seconds\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.72      0.71       478\n",
      "    positive       0.74      0.73      0.74       522\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.72      0.72      0.72      1000\n",
      "weighted avg       0.73      0.72      0.73      1000\n",
      "\n",
      "Building complete model and saving ...\n",
      "Complete model fit in 55.033 seconds\n",
      "Accuracy Score of Model: 72.5%\n",
      "====================================================================\n",
      "Classification Type: SVC(C=0.025, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Building for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation model fit in 97.945 seconds\n",
      "Classification Report:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       481\n",
      "    positive       0.52      1.00      0.68       519\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.26      0.50      0.34      1000\n",
      "weighted avg       0.27      0.52      0.35      1000\n",
      "\n",
      "Building complete model and saving ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete model fit in 144.702 seconds\n",
      "Accuracy Score of Model: 51.9%\n",
      "====================================================================\n",
      "Classification Type: NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "      decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "      kernel='rbf', max_iter=-1, nu=0.1, probability=True, random_state=None,\n",
      "      shrinking=True, tol=0.001, verbose=False)\n",
      "Building for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation model fit in 47.516 seconds\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.98      0.73       509\n",
      "    positive       0.93      0.29      0.44       491\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.76      0.63      0.59      1000\n",
      "weighted avg       0.76      0.64      0.59      1000\n",
      "\n",
      "Building complete model and saving ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete model fit in 60.883 seconds\n",
      "Accuracy Score of Model: 63.9%\n",
      "====================================================================\n",
      "Classification Type: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "Building for evaluation\n",
      "Evaluation model fit in 42.785 seconds\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.69      0.69       489\n",
      "    positive       0.71      0.72      0.71       511\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.70      0.70      0.70      1000\n",
      "weighted avg       0.70      0.70      0.70      1000\n",
      "\n",
      "Building complete model and saving ...\n",
      "Complete model fit in 56.187 seconds\n",
      "Accuracy Score of Model: 70.39999999999999%\n",
      "====================================================================\n",
      "Classification Type: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Building for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation model fit in 42.570 seconds\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.82      0.74       485\n",
      "    positive       0.79      0.63      0.70       515\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.73      0.72      0.72      1000\n",
      "weighted avg       0.73      0.72      0.72      1000\n",
      "\n",
      "Building complete model and saving ...\n",
      "Complete model fit in 55.264 seconds\n",
      "Accuracy Score of Model: 72.1%\n",
      "====================================================================\n",
      "Classification Type: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "Building for evaluation\n",
      "Evaluation model fit in 45.317 seconds\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.73      0.77       499\n",
      "    positive       0.75      0.83      0.79       501\n",
      "\n",
      "    accuracy                           0.78      1000\n",
      "   macro avg       0.78      0.78      0.78      1000\n",
      "weighted avg       0.78      0.78      0.78      1000\n",
      "\n",
      "Building complete model and saving ...\n",
      "Complete model fit in 55.723 seconds\n",
      "Accuracy Score of Model: 77.8%\n",
      "====================================================================\n",
      "Classification Type: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Building for evaluation\n",
      "Evaluation model fit in 52.252 seconds\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.70      0.77       513\n",
      "    positive       0.73      0.86      0.79       487\n",
      "\n",
      "    accuracy                           0.78      1000\n",
      "   macro avg       0.79      0.78      0.78      1000\n",
      "weighted avg       0.79      0.78      0.78      1000\n",
      "\n",
      "Building complete model and saving ...\n",
      "Complete model fit in 65.025 seconds\n",
      "Accuracy Score of Model: 78.0%\n",
      "====================================================================\n",
      "Classification Type: SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Building for evaluation\n",
      "Evaluation model fit in 42.899 seconds\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83       500\n",
      "    positive       0.82      0.87      0.84       500\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.84      0.84      0.84      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n",
      "Building complete model and saving ...\n",
      "Complete model fit in 53.666 seconds\n",
      "Accuracy Score of Model: 83.8%\n",
      "====================================================================\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "n = 0 \n",
    "classifier_accuracy_score = {}\n",
    "for classifier in classifiers:\n",
    "    name = classifier_names[n]\n",
    "    n += 1 \n",
    "    print(\"Classification Type: {}\".format(classifier))\n",
    "    model, score = build_and_evaluate(X=X,y=y, classifier=classifier)#, outpath=PATH)\n",
    "    #did not set outpath=PATH because do not want the model to write to the file everytime. Only if model has the highest accuracy score \n",
    "    if n == 1: \n",
    "        previous_score = score\n",
    "        with open(PATH, 'wb') as f:\n",
    "            pickle.dump(model, f) #pickel save object and load it back in again           \n",
    "    elif score > previous_score:  #will only overwrite pickel file with new model if the accuracy score is higher than the previously highest score \n",
    "        previous_score = score \n",
    "        with open(PATH, 'wb') as f:\n",
    "            pickle.dump(model, f) #pickel save object and load it back in again \n",
    "    print(\"Accuracy Score of Model: {}%\".format(score *100))\n",
    "    print(\"====================================================================\")\n",
    "    classifier_accuracy_score[name] = score\n",
    "print(\"done.\")            \n",
    "#     pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                       ('classifier', classifier)])\n",
    "#     pipe.fit(X_train, y_train)   \n",
    "#     print(classifier)\n",
    "#     print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Use the Dictionary Created above, called classifier_accuracy_score, and create a pandas DataFrame that represents all classifers tested and their accuracy score. There will be two columns: classifier_name and accuracy_score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\n",
    "    \"classifer_name\": list(classifier_accuracy_score.keys()), \n",
    "    \"accuracy_score\": list(classifier_accuracy_score.values()), \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change accuracy_score column into a percentage by multiplying by 100 \n",
    "df[\"accuracy_score\"] = df[\"accuracy_score\"] *100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Plot the DataFrame created above, called df, to figure out the best classifier based on accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort df from lowest to highest \n",
    "df = df.sort_values(\"accuracy_score\", ascending= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"98048378-4ad0-42bc-b289-72cf39713f53\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"4d662d1f-42b8-4e91-a52e-9365907a368b\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1017\",\"type\":\"Grid\"},{\"id\":\"1021\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1018\",\"type\":\"CategoricalAxis\"}],\"plot_width\":800,\"renderers\":[{\"id\":\"1040\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1003\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1028\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1005\",\"type\":\"Range1d\"},\"x_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1007\",\"type\":\"FactorRange\"},\"y_scale\":{\"id\":\"1011\",\"type\":\"CategoricalScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis_label\":\"Accuracy Score (%)\",\"formatter\":{\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_color\":{\"value\":\"black\"},\"height\":{\"value\":0.4},\"right\":{\"field\":\"accuracy_score\"},\"y\":{\"field\":\"classifer_name\"}},\"id\":\"1039\",\"type\":\"HBar\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1019\",\"type\":\"CategoricalTicker\"}},\"id\":\"1021\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1035\",\"type\":\"ColumnDataSource\"}},\"id\":\"1041\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1051\",\"type\":\"Selection\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1022\",\"type\":\"PanTool\"},{\"id\":\"1023\",\"type\":\"WheelZoomTool\"},{\"id\":\"1024\",\"type\":\"BoxZoomTool\"},{\"id\":\"1025\",\"type\":\"SaveTool\"},{\"id\":\"1026\",\"type\":\"ResetTool\"},{\"id\":\"1027\",\"type\":\"HelpTool\"},{\"id\":\"1042\",\"type\":\"HoverTool\"}]},\"id\":\"1028\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"end\":100},\"id\":\"1005\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"callback\":null,\"factors\":[\"SVC\",\"NuSVC\",\"DecisionTreeClassifier\",\"RandomForestClassifier\",\"KNeighborsClassifier\",\"AdaBoostClassifier\",\"GradientBoostingClassifier\",\"SGDClassifier\"]},\"id\":\"1007\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"SaveTool\"},{\"attributes\":{\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"PanTool\"},{\"attributes\":{\"axis_label\":\"Classifier Type\",\"formatter\":{\"id\":\"1046\",\"type\":\"CategoricalTickFormatter\"},\"ticker\":{\"id\":\"1019\",\"type\":\"CategoricalTicker\"}},\"id\":\"1018\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"text\":\"Comparing the Accuracy Scores of Different Classifiers Tested\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"1035\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1037\",\"type\":\"HBar\"},\"hover_glyph\":{\"id\":\"1039\",\"type\":\"HBar\"},\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1038\",\"type\":\"HBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"1041\",\"type\":\"CDSView\"}},\"id\":\"1040\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"callback\":null,\"data\":{\"accuracy_score\":{\"__ndarray__\":\"MzMzMzPzSUAzMzMzM/NPQJmZmZmZmVFAZmZmZmYGUkAAAAAAACBSQDMzMzMzc1NAAAAAAACAU0AzMzMzM/NUQA==\",\"dtype\":\"float64\",\"shape\":[8]},\"classifer_name\":[\"SVC\",\"NuSVC\",\"DecisionTreeClassifier\",\"RandomForestClassifier\",\"KNeighborsClassifier\",\"AdaBoostClassifier\",\"GradientBoostingClassifier\",\"SGDClassifier\"],\"index\":[1,2,3,4,0,5,6,7]},\"selected\":{\"id\":\"1051\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1050\",\"type\":\"UnionRenderers\"}},\"id\":\"1035\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1049\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_color\":{\"value\":\"orange\"},\"height\":{\"value\":0.4},\"line_color\":{\"value\":\"orange\"},\"right\":{\"field\":\"accuracy_score\"},\"y\":{\"field\":\"classifer_name\"}},\"id\":\"1037\",\"type\":\"HBar\"},{\"attributes\":{\"overlay\":{\"id\":\"1049\",\"type\":\"BoxAnnotation\"}},\"id\":\"1024\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1027\",\"type\":\"HelpTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"height\":{\"value\":0.4},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"accuracy_score\"},\"y\":{\"field\":\"classifer_name\"}},\"id\":\"1038\",\"type\":\"HBar\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"Classifier\",\"@classifer_name\"],[\"% Accuracy Score\",\"@accuracy_score\"]]},\"id\":\"1042\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"WheelZoomTool\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"4d662d1f-42b8-4e91-a52e-9365907a368b\",\"roots\":{\"1002\":\"98048378-4ad0-42bc-b289-72cf39713f53\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'reset']\n",
    "p = figure(y_range =list(df[\"classifer_name\"]),\n",
    "           x_range = (0,100), \n",
    "           #x_range = (list(top_50_ingredients[\"Ingredients\"])),\n",
    "           plot_height=600,\n",
    "           plot_width=800,\n",
    "           x_axis_label='Accuracy Score (%)',\n",
    "           y_axis_label='Classifier Type',\n",
    "           title='''Comparing the Accuracy Scores of Different Classifiers Tested''',\n",
    "          )\n",
    "#Classifiers Tried and their Associated Accuracy Scores\n",
    "p.hbar(y='classifer_name', right= \"accuracy_score\", \n",
    "       left = 0, \n",
    "       height = 0.4, \n",
    "       color = \"orange\",  \n",
    "       hover_color=\"black\",\n",
    "       source = df)\n",
    "\n",
    "\n",
    "tooltips = [\n",
    "            ('Classifier','@classifer_name'),\n",
    "            ('% Accuracy Score','@accuracy_score')\n",
    "           ]\n",
    "\n",
    "# Add the HoverTool to the figure\n",
    "p.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of Findings: \n",
    "The SGDClassifier has the highest accuracy score. After making changes to the preprocessing section, the accuracy score is now 83.80% percent. The GradientBoostingClassifier is a comparatively good classifer, but is less accurate than the SGDClassifer. The  GradientBoostingClassifier has an accuracy score of 78%. As well, from the visualization you can see that SVC Classifier has the lowest accuracy score of 51.90%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tune the hyperparameters of SGDClassifier to increase the accuracy of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Tune the parameters of the model using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH, 'rb') as f:\n",
    "    rf_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'preprocessor', 'vectorizer', 'classifier', 'preprocessor__lower', 'preprocessor__punct', 'preprocessor__stopwords', 'preprocessor__strip', 'vectorizer__analyzer', 'vectorizer__binary', 'vectorizer__decode_error', 'vectorizer__dtype', 'vectorizer__encoding', 'vectorizer__input', 'vectorizer__lowercase', 'vectorizer__max_df', 'vectorizer__max_features', 'vectorizer__min_df', 'vectorizer__ngram_range', 'vectorizer__norm', 'vectorizer__preprocessor', 'vectorizer__smooth_idf', 'vectorizer__stop_words', 'vectorizer__strip_accents', 'vectorizer__sublinear_tf', 'vectorizer__token_pattern', 'vectorizer__tokenizer', 'vectorizer__use_idf', 'vectorizer__vocabulary', 'classifier__alpha', 'classifier__average', 'classifier__class_weight', 'classifier__early_stopping', 'classifier__epsilon', 'classifier__eta0', 'classifier__fit_intercept', 'classifier__l1_ratio', 'classifier__learning_rate', 'classifier__loss', 'classifier__max_iter', 'classifier__n_iter_no_change', 'classifier__n_jobs', 'classifier__penalty', 'classifier__power_t', 'classifier__random_state', 'classifier__shuffle', 'classifier__tol', 'classifier__validation_fraction', 'classifier__verbose', 'classifier__warm_start'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.get_params().keys()\n",
    "#review parameters you can use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "After reviewing the parameters of the model, and doing research online, I am going to improve the model by tuning the hyperparameter called classifier__max_iter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "                 'classifier__max_iter': [5, 100, 500, 1000]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(rf_model, param_grid, cv=5)\n",
    "#grid_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/Sammie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        NLTKPreprocessor(lower=True,\n",
       "                                                         punct={'!', '\"', '#',\n",
       "                                                                '$', '%', '&',\n",
       "                                                                \"'\", '(', ')',\n",
       "                                                                '*', '+', ',',\n",
       "                                                                '-', '.', '/',\n",
       "                                                                ':', ';', '<',\n",
       "                                                                '=', '>', '?',\n",
       "                                                                '@', '[', '\\\\',\n",
       "                                                                ']', '^', '_',\n",
       "                                                                '`', '{', '|', ...},\n",
       "                                                         stopwords={'0', '1',\n",
       "                                                                    '2', '3',\n",
       "                                                                    '4', '5',\n",
       "                                                                    '6', '7',\n",
       "                                                                    '8', '9',\n",
       "                                                                    'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again...\n",
       "                                                      loss='hinge',\n",
       "                                                      max_iter=1000,\n",
       "                                                      n_iter_no_change=5,\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=None,\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'classifier__max_iter': [5, 100, 500, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_iter': 500}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "The best parameters for the model is when max_iter equals 500. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Calculate accuracy score for this better model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = grid_clf.cv_results_['std_test_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.850 (+/-0.014) for {'classifier__max_iter': 5}\n",
      "Accuracy: 0.849 (+/-0.015) for {'classifier__max_iter': 100}\n",
      "Accuracy: 0.850 (+/-0.018) for {'classifier__max_iter': 500}\n",
      "Accuracy: 0.848 (+/-0.016) for {'classifier__max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "for mean, std, params in zip(means, stds, grid_clf.cv_results_['params']):\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f) for %r\" %\n",
    "#           (mean,std * 2, params))\n",
    "    print(\"Accuracy: %0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: \n",
    "Before tuning the hyperparameters, the accuracy score of the SGDClassifier was 83.80%. After tuning the hyperparameters, I found that the best parameter, from the different values tested (5, 100, 500, and 1000), is when when max_iter = 500. When max_iter equals 500, the accuracy of the model increased. The accuracy of the new model is now 0.850, or 85.00%. Although, it is important to note that when max_iter equals 5 it appears to have the same accuracy score of 85.00%. Although, when using the attribute best_params_ the result was max_iter equals 500. Therefore, the accuracy score when max_iter equals 500 must be slightly higher than the accuracy score when max_iter equals 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Now, assign the best estimator to the variable best_model. After,  overwrite the pickle file and dump best_model to the pickle file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the best model from grid_clf using the attribute best_estimator_ and \n",
    "#assign it to the variable best_model\n",
    "\n",
    "best_model = grid_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load old model - this is done just in case i need to reference the old model later. I assigned the old model\n",
    "#to the variable model_before\n",
    "\n",
    "with open(PATH, 'rb') as f:\n",
    "    model_before = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the best_model into the pickle file \n",
    "\n",
    "with open(PATH, 'wb') as f:\n",
    "    pickle.dump(best_model, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Now, get predicted labels for the sample dataset used, and compare predicted labels with Acutal labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) get the predicted labels for the best model using m[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the pickle file and load in the model (now it will be the best model with the tuned hyperparameters found above)\n",
    "with open(PATH, 'rb') as f:\n",
    "    model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = model.predict(m[\"review\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'positive', ..., 'negative', 'positive',\n",
       "       'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Create a copy of the DataFrame m, and assign it to the variable sentiment_for_IMBD. The DataFrame sentiment_for_IMBD will be altered and used throughout the code. \n",
    "- I am going to add columns to this DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the DataFrame and assign it the variable \n",
    "sentiment_for_IMBD = m.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11936</th>\n",
       "      <td>I liked this film very much. The story jumps b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30205</th>\n",
       "      <td>Dear me. Where do I start? The dad isn't anywh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48567</th>\n",
       "      <td>I saw The D's new film tonight at a special ad...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36385</th>\n",
       "      <td>The only reason I bought the DVD was to satisf...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31602</th>\n",
       "      <td>I have never been a great fan of Oliver Stone,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "11936  I liked this film very much. The story jumps b...  positive\n",
       "30205  Dear me. Where do I start? The dad isn't anywh...  negative\n",
       "48567  I saw The D's new film tonight at a special ad...  positive\n",
       "36385  The only reason I bought the DVD was to satisf...  negative\n",
       "31602  I have never been a great fan of Oliver Stone,...  positive"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_for_IMBD.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Create a column in sentiment_for_IMBD called predicted. This column will have the predicted sentiment  labels that are assigned to the variable predicted_labels, which was found above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_for_IMBD[\"predicted\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the sentiment labels in the predicted column with negative or positive \n",
    "sentiment_for_IMBD[\"predicted\"].replace(to_replace = {0:\"negative\", \n",
    "                                                      1: \"positive\",\n",
    "                                                      \"pos\": \"positive\", \n",
    "                                                      \"neg\": \"negative\"\n",
    "                                                     }, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) create a grouped bar graph using bokeh that compares the number of correctly predicted sentiment labels with incorrectly predicted sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter sentiment_for_IMBD for correctly predicted labels  \n",
    "correct_sent = sentiment_for_IMBD[\n",
    "                                sentiment_for_IMBD['sentiment'] == sentiment_for_IMBD['predicted']\n",
    "                                 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11936</th>\n",
       "      <td>I liked this film very much. The story jumps b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30205</th>\n",
       "      <td>Dear me. Where do I start? The dad isn't anywh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48567</th>\n",
       "      <td>I saw The D's new film tonight at a special ad...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36385</th>\n",
       "      <td>The only reason I bought the DVD was to satisf...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31602</th>\n",
       "      <td>I have never been a great fan of Oliver Stone,...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment predicted\n",
       "11936  I liked this film very much. The story jumps b...  positive  positive\n",
       "30205  Dear me. Where do I start? The dad isn't anywh...  negative  negative\n",
       "48567  I saw The D's new film tonight at a special ad...  positive  positive\n",
       "36385  The only reason I bought the DVD was to satisf...  negative  negative\n",
       "31602  I have never been a great fan of Oliver Stone,...  positive  positive"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter sentiment_for_IMBD for incorrectly predicted labels \n",
    "incorrect_sent = sentiment_for_IMBD[sentiment_for_IMBD['sentiment'] != sentiment_for_IMBD['predicted']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35972</th>\n",
       "      <td>let me first just say that in the past, i have...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15064</th>\n",
       "      <td>This movie was pure genius. John Waters is bri...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>Mickey Rourke hunts Diane Lane in Elmore Leona...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15153</th>\n",
       "      <td>Comedy Central has had success with original p...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23354</th>\n",
       "      <td>I was really surprised with this movie. Going ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment predicted\n",
       "35972  let me first just say that in the past, i have...  negative  positive\n",
       "15064  This movie was pure genius. John Waters is bri...  negative  positive\n",
       "1216   Mickey Rourke hunts Diane Lane in Elmore Leona...  negative  positive\n",
       "15153  Comedy Central has had success with original p...  negative  positive\n",
       "23354  I was really surprised with this movie. Going ...  positive  negative"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of correctly predicted labels \n",
    "correct_sentiment= correct_sent.groupby(\"sentiment\")[\"predicted\"] \\\n",
    "    .count() \\\n",
    "    .reset_index(name =\"Number_Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Number_Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>2445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>2533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  Number_Correct\n",
       "0  negative            2445\n",
       "1  positive            2533"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of incorrectly predicted labels \n",
    "incorrect_sentiment=incorrect_sent.groupby(\"sentiment\")[\"predicted\"] \\\n",
    "    .count() \\\n",
    "    .reset_index(name =\"Number_Incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Number_Incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  Number_Incorrect\n",
       "0  negative                10\n",
       "1  positive                12"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the two dataframes correct_sentiment and incorrect_sentiment to get combined counts\n",
    "correct_and_incorrect= incorrect_sentiment.merge(correct_sentiment, on = \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Number_Incorrect</th>\n",
       "      <th>Number_Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>10</td>\n",
       "      <td>2445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>12</td>\n",
       "      <td>2533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  Number_Incorrect  Number_Correct\n",
       "0  negative                10            2445\n",
       "1  positive                12            2533"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_and_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below creates a grouped bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"fa0a7b4e-9cb9-4b23-bf26-c625a89c4eca\" data-root-id=\"1102\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"4c3643e3-c6a8-4f6c-b7ac-be35a3759b89\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1112\",\"type\":\"CategoricalAxis\"}],\"center\":[{\"id\":\"1115\",\"type\":\"Grid\"},{\"id\":\"1120\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1116\",\"type\":\"LinearAxis\"}],\"plot_height\":500,\"renderers\":[{\"id\":\"1138\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1103\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1127\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1101\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"1108\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"1106\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1110\",\"type\":\"LinearScale\"}},\"id\":\"1102\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1157\",\"type\":\"Selection\"},{\"attributes\":{\"axis_label\":\"Number of Total Labels Predicted\",\"formatter\":{\"id\":\"1152\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1117\",\"type\":\"BasicTicker\"}},\"id\":\"1116\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1124\",\"type\":\"SaveTool\"},{\"attributes\":{\"axis_label\":\"Sentiment\",\"formatter\":{\"id\":\"1154\",\"type\":\"CategoricalTickFormatter\"},\"ticker\":{\"id\":\"1113\",\"type\":\"CategoricalTicker\"}},\"id\":\"1112\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"overlay\":{\"id\":\"1155\",\"type\":\"BoxAnnotation\"}},\"id\":\"1123\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1110\",\"type\":\"LinearScale\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1117\",\"type\":\"BasicTicker\"}},\"id\":\"1120\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1154\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{},\"id\":\"1152\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"text\":\"Comparing Accuracy of Predicted Labels by Sentiment\"},\"id\":\"1103\",\"type\":\"Title\"},{\"attributes\":{\"grid_line_color\":null,\"ticker\":{\"id\":\"1113\",\"type\":\"CategoricalTicker\"}},\"id\":\"1115\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"counts\",\"@counts\"],[\"Category\",\"@x\"]]},\"id\":\"1140\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1125\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1126\",\"type\":\"HelpTool\"},{\"attributes\":{\"data_source\":{\"id\":\"1100\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1136\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1137\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"1139\",\"type\":\"CDSView\"}},\"id\":\"1138\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"end\":2,\"factors\":[\"incorrect\",\"correct\"],\"palette\":[\"tomato\",\"#3CB371\"],\"start\":1},\"id\":\"1134\",\"type\":\"CategoricalColorMapper\"},{\"attributes\":{},\"id\":\"1113\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"source\":{\"id\":\"1100\",\"type\":\"ColumnDataSource\"}},\"id\":\"1139\",\"type\":\"CDSView\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1121\",\"type\":\"PanTool\"},{\"id\":\"1122\",\"type\":\"WheelZoomTool\"},{\"id\":\"1123\",\"type\":\"BoxZoomTool\"},{\"id\":\"1124\",\"type\":\"SaveTool\"},{\"id\":\"1125\",\"type\":\"ResetTool\"},{\"id\":\"1126\",\"type\":\"HelpTool\"},{\"id\":\"1140\",\"type\":\"HoverTool\"}]},\"id\":\"1127\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1108\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"1121\",\"type\":\"PanTool\"},{\"attributes\":{\"callback\":null,\"factors\":[[\"negative\",\"incorrect\"],[\"negative\",\"correct\"],[\"positive\",\"incorrect\"],[\"positive\",\"correct\"]],\"range_padding\":0.01},\"id\":\"1101\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1117\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_color\":{\"field\":\"x\",\"transform\":{\"id\":\"1134\",\"type\":\"CategoricalColorMapper\"}},\"line_color\":{\"value\":\"white\"},\"top\":{\"field\":\"counts\"},\"width\":{\"value\":1},\"x\":{\"field\":\"x\"}},\"id\":\"1136\",\"type\":\"VBar\"},{\"attributes\":{\"callback\":null,\"start\":0},\"id\":\"1106\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"counts\"},\"width\":{\"value\":1},\"x\":{\"field\":\"x\"}},\"id\":\"1137\",\"type\":\"VBar\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1155\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"callback\":null,\"data\":{\"counts\":[10,2445,12,2533],\"x\":[[\"negative\",\"incorrect\"],[\"negative\",\"correct\"],[\"positive\",\"incorrect\"],[\"positive\",\"correct\"]]},\"selected\":{\"id\":\"1157\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1156\",\"type\":\"UnionRenderers\"}},\"id\":\"1100\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1122\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1156\",\"type\":\"UnionRenderers\"}],\"root_ids\":[\"1102\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"4c3643e3-c6a8-4f6c-b7ac-be35a3759b89\",\"roots\":{\"1102\":\"fa0a7b4e-9cb9-4b23-bf26-c625a89c4eca\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1102"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import FactorRange\n",
    "sentiments = list(correct_and_incorrect['sentiment'])\n",
    "right_or_wrong = ['incorrect', 'correct']\n",
    "\n",
    "data = {'sentiment': sentiments, \n",
    "        'incorrect': list(correct_and_incorrect['Number_Incorrect']),\n",
    "        'correct': list(correct_and_incorrect['Number_Correct'])}\n",
    "\n",
    "# data\n",
    "\n",
    "x = [(c, rw) for c in sentiments for rw in right_or_wrong]\n",
    "counts = sum(zip(data['incorrect'], data['correct']), ())\n",
    "\n",
    "\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=x, counts=counts))\n",
    "\n",
    "plot = figure(x_range=FactorRange(*x), plot_height=500, plot_width=600, title=\"Comparing Accuracy of Predicted Labels by Sentiment\")\n",
    "\n",
    "plot.vbar(x='x', top='counts', width=1, source=source, line_color='white',\n",
    "          fill_color=factor_cmap('x', palette=['tomato', '#3CB371'], factors=right_or_wrong, start=1, end=2))\n",
    "    \n",
    "plot.y_range.start = 0\n",
    "plot.x_range.range_padding = 0.01\n",
    "# plot.xaxis.major_label_orientation = 1.55\n",
    "# plot.xaxis.group_label_orientation = 1\n",
    "plot.xgrid.grid_line_color = None\n",
    "plot.xaxis.axis_label = 'Sentiment'\n",
    "plot.yaxis.axis_label = 'Number of Total Labels Predicted'\n",
    "\n",
    "tooltips = [\n",
    "            ('counts','@counts'),\n",
    "            ('Category','@x')\n",
    "           ]\n",
    "\n",
    "# Add the HoverTool to the figure\n",
    "plot.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "This grouped bar graph shows the number of labels that were predicted accurately and inaccurately for both negative sentiment and positive sentiment. For negative sentiment, 2,445 reviews were correctly predicted as having negative sentiment. On the other hand, 10 reviews were inaccurately predicted as having negative sentiment. Similarly, 2,533 reviews were correctly predicted as having positive sentiment, and 12 reviews were inaccurately predicted as having positive sentiment. The model appears to be working well because a majority of the sentiment labels are being correctly classified. This is shown by the fact that only 10 labels for negative senitment were classified incorrectly, and 12 labels for positive sentiment were classified incorrectly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Create a Confusion Matrix using the heatmap visualization in seaborn to review the number of  false positives, true positives, false negatives, and true negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_for_IMBD[\"Actual Sentiment\"] = sentiment_for_IMBD[\"sentiment\"] \n",
    "sentiment_for_IMBD[\"Predicted Sentiment\"] = sentiment_for_IMBD[\"predicted\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(sentiment_for_IMBD[\"Predicted Sentiment\"], sentiment_for_IMBD[\"Actual Sentiment\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual Sentiment</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>2445</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>10</td>\n",
       "      <td>2533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual Sentiment     negative  positive\n",
       "Predicted Sentiment                    \n",
       "negative                 2445        12\n",
       "positive                   10      2533"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12b661748>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(ct, annot = True, cmap=sns.color_palette(\"BrBG\"),fmt=\"d\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "This heatmap shows a confusion matrix. The confusion matrix depicts the number of false positives, true positives, false negatives, and true negatives that are being classified by the model. \"The confusion matrix shows the ways in which your classification model is confused when it makes predictions\"(https://www.geeksforgeeks.org/confusion-matrix-machine-learning/). \n",
    "\n",
    "Here, you can see that there are more true positives than false positives. As well, there is more true negatives than false negatives. Therefore, our model has predicted a majority of the labels accurately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perfom Professor Teplovs orginial code that was in the notebook and get an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes made the model return the accuracy score and the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('preprocessor',\n",
      "                 NLTKPreprocessor(lower=True,\n",
      "                                  punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
      "                                         ')', '*', '+', ',', '-', '.', '/', ':',\n",
      "                                         ';', '<', '=', '>', '?', '@', '[',\n",
      "                                         '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
      "                                  stopwords={'0', '1', '2', '3', '4', '5', '6',\n",
      "                                             '7', '8', '9', 'a', 'about',\n",
      "                                             'above', 'after', 'again',\n",
      "                                             'against', 'ain', 'all', 'am',\n",
      "                                             'an', 'and', 'any', 'are', 'aren',\n",
      "                                             \"...\n",
      "                ('classifier',\n",
      "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
      "                               fit_intercept=True, l1_ratio=0.15,\n",
      "                               learning_rate='optimal', loss='hinge',\n",
      "                               max_iter=500, n_iter_no_change=5, n_jobs=None,\n",
      "                               penalty='l2', power_t=0.5, random_state=None,\n",
      "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "                               verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "['negative' 'positive' 'negative' 'negative']\n"
     ]
    }
   ],
   "source": [
    "# You should include the output from the following code in your notebook:\n",
    "#with open(\"PATH_TO_YOUR_IMDB_MODEL\", 'rb') as f:\n",
    "with open(PATH, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "yhat = model.predict([\n",
    "    \"This is the worst movie I have ever seen!\",\n",
    "    \"The movie was great action packed and full of adventure!\",\n",
    "    \"Wow!\",\n",
    "    \"This was the best and the worst at the same time!\"\n",
    "])\n",
    "\n",
    "print(model)\n",
    "print(yhat)\n",
    "#print(model.labels_.inverse_transform(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5587      excellent    -5.9002            bad\n",
      "3.2211          great    -4.1733          waste\n",
      "2.9065        perfect    -4.0393         boring\n",
      "2.4466            fun    -3.5487          awful\n",
      "2.2438            job    -3.5158        nothing\n",
      "2.1418      fantastic    -2.8812       terrible\n",
      "2.1244       favorite    -2.7944           poor\n",
      "2.1055      wonderful    -2.6576         minute\n",
      "2.0794          enjoy    -2.5629           dull\n",
      "2.0776     especially    -2.5172     ridiculous\n",
      "2.0644           best    -2.3295    forgettable\n",
      "2.0208           seat    -2.3073           fail\n",
      "1.9387         subtle    -2.1062           weak\n",
      "1.9115           love    -2.0984         script\n",
      "1.8793          worth    -2.0859       horrible\n",
      "1.8575      recommend    -2.0756      laughable\n",
      "1.8538            yet    -2.0622          might\n",
      "1.7871           hook    -2.0507           lack\n",
      "1.7831      enjoyable    -2.0373         mildly\n",
      "1.7691     unexpected    -2.0162        suppose\n"
     ]
    }
   ],
   "source": [
    "print(show_most_informative_features(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "\n",
    "Above shows a list of the most informative features for the model. In other words, the output allows the user to see the words that are most highly associated with each sentiment. \n",
    "\n",
    "These words are important in predicting the sentiment label for a review. The top 3 words that help predict positive sentiment are words excellent, great, and perfect. The top 3 words that help predict whether a review has negative sentiment are words bad, waste, and boring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
